\documentclass{unitothesis}

% \includeonly{}

% Packages for TikZ NNs
\usepackage{listofitems} % for \readlist to create arrays
\usetikzlibrary{arrows.meta} % for arrow size
\usepackage[outline]{contour} % glow around text
\contourlength{1.4pt}

% Colors for TikZ NNs
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}

% Styles for TikZ NNs
\tikzset{
    >=latex, % for default LaTeX arrow head
    node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},
    node bias/.style={node,black!90,draw=black,fill=black!25},
    node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},
    node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},
    node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},
    connect/.style={thick,mydarkblue}, %,line cap=round
    connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1},
    node 0/.style={node bias}, % node styles, numbered for easy mapping with \nstyle
    node 1/.style={node in},
    node 2/.style={node hidden},
    node 3/.style={node out}
}
\def\nstyle{int(\curr<\Nnodlen?min(2,\curr):3)} % map layer number onto 1, 2, or 3

% Reset section counter after new part
\usepackage{chngcntr}
\counterwithin*{section}{part}
\setcounter{tocdepth}{1} % hide subsections and lower from TOC

% Useful commands for this project
\newcommand{\J}{\mathcal{J}}
\newcommand{\mono}[1]{\texttt{#1}}
\newcommand{\mfnet}{\mono{mfnet}\xspace}
\newcommand{\pytorch}{\mono{PyTorch}\xspace}
\newcommand{\shape}[2]{$#1\times #2$}
\newcommand{\wrt}{with respect to\xspace}
\newcommand{\nin}{n_\text{in}}
\newcommand{\nout}{n_\text{out}}

% Acronyms
\acrodef{FFCNN}{Feedforward Fully Connected Neural Network}
\acrodef{MSE}{Mean Squared Error}
\acrodef{CE}{Cross Entropy}
\acrodef{NN}{Neural Network}
\acrodef{GD}{Gradient Descent}
\acrodef{SGD}{Stochastic Gradient Descent}

\DeclareSIUnit\pixel{px}

\author{Francesco Marchisotti}
\title{\centering\mfnet \sc-- A simple\\[0.5em] Machine Learning Library}
\aayear{2024/2025}

\begin{supervisors}
   \supervisor{}{}{\sc Matteo Osella}
\end{supervisors}

\begin{document}

\maketitlepage
\thispagestyle{empty}
\subsection*{\centering Abstract}
Modern machine learning libraries such as \pytorch and \mono{TensorFlow} are widely used in both academia and industry. They are highly optimized, feature-rich, and provide extensive support for various machine learning tasks. In addition to their extensive features, these libraries are designed to efficiently leverage modern GPUs to significantly speed up training and inference for large-scale machine learning models.

To gain a deeper understanding of the workings of such libraries, \mfnet was developed as a simplified neural network library from scratch. The main objective was to implement a functional framework, focusing on the core concept of backpropagation.

The effectiveness of the library was validated by analyzing learning curves on two benchmark tasks: regression and classification. The results demonstrate that \mfnet successfully learns and generalizes, confirming the correctness of its implementation.

\newpage

{\hypersetup{linkcolor=black}\tableofcontents}

\include{Files/signal-flow}
\include{Files/part-1-implementation}
\include{Files/part-2-comparison}

\appendix
\include{Files/Appendix/exec-times}
\include{Files/Appendix/example}

\end{document}
