\documentclass{unitothesis}

% \includeonly{}

% Packages for TikZ NNs
\usepackage{listofitems} % for \readlist to create arrays
\usetikzlibrary{arrows.meta} % for arrow size
\usepackage[outline]{contour} % glow around text
\contourlength{1.4pt}

% Colors for TikZ NNs
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}

% Styles for TikZ NNs
\tikzset{
    >=latex, % for default LaTeX arrow head
    node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},
    node bias/.style={node,black!90,draw=black,fill=black!25},
    node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},
    node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},
    node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},
    connect/.style={thick,mydarkblue}, %,line cap=round
    connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1},
    node 0/.style={node bias}, % node styles, numbered for easy mapping with \nstyle
    node 1/.style={node in},
    node 2/.style={node hidden},
    node 3/.style={node out}
}
\def\nstyle{int(\curr<\Nnodlen?min(2,\curr):3)} % map layer number onto 1, 2, or 3

% Reset section counter after new part
\usepackage{chngcntr}
\counterwithin*{section}{part}

% Useful commands for this project
\newcommand{\J}{\mathcal{J}}
\newcommand{\mono}[1]{\texttt{#1}}
\newcommand{\mfnet}{\mono{mfnet}\xspace}
\newcommand{\pytorch}{\mono{PyTorch}\xspace}
\newcommand{\shape}[2]{$#1\times #2$}
\newcommand{\wrt}{with respect to\xspace}
\newcommand{\nin}{n_\text{in}}
\newcommand{\nout}{n_\text{out}}

% Acronyms
\acrodef{FFCNN}{Feedforward Fully Connected Neural Network}
\acrodef{MSE}{Mean Squared Error}
\acrodef{CE}{Cross Entropy}
\acrodef{NN}{Neural Network}
\acrodef{GD}{Gradient Descent}
\acrodef{SGD}{Stochastic Gradient Descent}

\author{Francesco Marchisotti}
\title{\centering\mfnet \sc-- A simple\\[0.5em] Machine Learning Library}
\aayear{2024/2025}

\begin{supervisors}
   \supervisor{}{}{\sc Matteo Osella}
\end{supervisors}

\begin{document}

\maketitlepage
\thispagestyle{empty}
\subsection*{\centering Abstract}
This document presents \mfnet, a simple machine learning library developed as a final project for the Deep Learning course. The key feature is the implementation of the backpropagation algorithm, enabling the training of \aclp*{NN} through gradient descent.

The library is then compared with \pytorch on two simple tasks: a regression on the California Housing dataset and a classification on the MNIST dataset.
\newpage

{\hypersetup{linkcolor=black}\tableofcontents}

\include{Files/signal-flow}

\include{Files/Part1/tensor}
\include{Files/Part1/backprop}
\include{Files/Part1/layer}
\include{Files/Part1/loss}
\include{Files/Part1/nn-optim-data}
\include{Files/Part1/train}
\include{Files/Part1/train-utils}

\include{Files/Part2/regression}
\include{Files/Part2/classification}
\include{Files/Part2/exec-times}

\appendix

\newpage
\include{Files/Appendix/example}

\end{document}

% Part 2: comparison with pytorch
% \begin{enumerate}
%     \item Regression task
%     \item Classification task
% \end{enumerate}
