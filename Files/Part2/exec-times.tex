\section*{A note on execution times}
It is interesting to note the execution times of the training loops for both libraries, shown in \cref{tab:regr_times,tab:class_times}. All training was done on a MacBook Pro 2019 with a 2.3 GHz Quad-Core Intel Core i7 processor, as \mfnet can't run on GPUs.

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
    \hline
    Model & \mfnet & \pytorch \\
    \hline
    Naive Mean Predictor & $\SI{0.0}{\s}$ & $\SI{0.0}{\s}$ \\
    Linear Regression & $\SI{1.1}{\s}$ & $\SI{66.0}{\s}$ \\
    Neural Network & $\SI{274.7}{\s}$ & $\SI{136.8}{\s}$ \\
    \hline
\end{tabular}
\caption{Execution times for regression training loops.}
\label{tab:regr_times}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
    \hline
    Model & \mfnet & \pytorch \\
    \hline
    Linear Classification & $\SI{150.6}{\s}$ & $\SI{709.4}{\s}$ \\
    Neural Network & $\SI{423.7}{\s}$ & $\SI{813.6}{\s}$ \\
    \hline
\end{tabular}
\caption{Execution times for classification training loops.}
\label{tab:class_times}
\end{table}

With the exception of the \acl{NN} in the regression task, \mfnet is almost always significantly faster than \pytorch. This is probably due to the fact that \pytorch is a highly optimised library but also extremely complex library with GPU support, while \mfnet is a simple implementation.

In the classification task, the batch size was different between the two frameworks, and this contributes to the longer training time of \pytorch.

Finally, the models trained were also quite simple, with the \aclp{NN} having at most one hidden layer. This means that the execution times may not fully represent the capabilities of each library when dealing with more complex architectures.
