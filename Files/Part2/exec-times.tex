\section*{A note on execution times}
It is interesting to note the execution times of the training loops for both libraries, shown in \cref{tab:regr_times,tab:class_times}. All training was done on a MacBook Pro 2019 with a 2.3 GHz Quad-Core Intel Core i7 processor, as \mfnet can't run on GPUs.

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
    \hline
    Model & \mfnet & \pytorch \\
    \hline
    Naive Mean Predictor & $\SI{0.0}{\s}$ & $\SI{0.0}{\s}$ \\
    Linear Regression & $\SI{1.1}{\s}$ & $\SI{66.0}{\s}$ \\
    Neural Network & $\SI{274.7}{\s}$ & $\SI{136.8}{\s}$ \\
    \hline
\end{tabular}
\caption{Execution times for regression training loops.}
\label{tab:regr_times}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
    \hline
    Model & \mfnet & \pytorch \\
    \hline
    Linear Classification & $\SI{150.6}{\s}$ & $\SI{709.4}{\s}$ \\
    Neural Network & $\SI{423.7}{\s}$ & $\SI{813.6}{\s}$ \\
    \hline
\end{tabular}
\caption{Execution times for classification training loops.}
\label{tab:class_times}
\end{table}

While \mfnet is almost always significantly faster that \pytorch, \pytorch's times are more consistent between models. This is probably due to the fact that \pytorch is a highly optimised library (for GPUs), while \mfnet is a simple implementation: the advantage of \mfnet likely comes from its simplicity, while the more consistent times of \pytorch show that it's a more mature library.

In the classification task, the batch size was different between the two frameworks, and this contributes to the longer training time of \pytorch.

Finally, the models trained were also quite simple, with the \aclp{NN} having at most one hidden layer. This means that the execution times may not fully represent the capabilities of each library when dealing with more complex architectures.
